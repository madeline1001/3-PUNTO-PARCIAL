{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_6oetW8f7A6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_X8Xypo_gIye",
        "outputId": "9095ebfd-480d-47bb-a1ec-5f6db4778b1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 169001437/169001437 [00:18<00:00, 9151321.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n"
          ]
        }
      ],
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),  \n",
        "    transforms.RandomHorizontalFlip(),  \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
        "])\n",
        "\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
        "\n",
        "# Dividir el dataset en entrenamiento (80%), validación (10%), y prueba (10%)\n",
        "train_size = int(0.8 * len(trainset))\n",
        "val_size = int(0.1 * len(trainset))\n",
        "test_size = len(trainset) - train_size - val_size\n",
        "trainset, valset, testset = random_split(trainset, [train_size, val_size, test_size])\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=False, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpfXjlIRggxQ",
        "outputId": "7abb98ef-6d76-489b-d561-c420586a8f40"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 199MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torchvision.models as models\n",
        "model = models.resnet18(pretrained=True)  \n",
        "model.fc = nn.Linear(512, 100)  \n",
        "model = model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "\n",
        "# Definir el optimizador, función de pérdida y scheduler para ajustar la tasa de aprendizaje\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "# Función de entrenamiento\n",
        "def train_model(epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  # Imprimir cada 100 mini-batches\n",
        "            print(f\"[{epoch+1}, {i+1}] pérdida: {running_loss / 100:.3f}\")\n",
        "            running_loss = 0.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpDhuZvFgjnn",
        "outputId": "985bf2cd-fda4-413b-acc5-23effa8ef089"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Época 1\n",
            "[1, 100] pérdida: 0.859\n",
            "[1, 200] pérdida: 0.859\n",
            "[1, 300] pérdida: 0.863\n",
            "[1, 400] pérdida: 0.826\n",
            "[1, 500] pérdida: 0.868\n",
            "[1, 600] pérdida: 0.877\n",
            "Precisión en validación: 56.22%\n",
            "Época 2\n",
            "[2, 100] pérdida: 0.881\n",
            "[2, 200] pérdida: 0.855\n",
            "[2, 300] pérdida: 0.850\n",
            "[2, 400] pérdida: 0.846\n",
            "[2, 500] pérdida: 0.861\n",
            "[2, 600] pérdida: 0.856\n",
            "Precisión en validación: 56.84%\n",
            "Época 3\n",
            "[3, 100] pérdida: 0.828\n",
            "[3, 200] pérdida: 0.850\n",
            "[3, 300] pérdida: 0.852\n",
            "[3, 400] pérdida: 0.833\n",
            "[3, 500] pérdida: 0.872\n",
            "[3, 600] pérdida: 0.873\n",
            "Precisión en validación: 56.42%\n",
            "Época 4\n",
            "[4, 100] pérdida: 0.864\n",
            "[4, 200] pérdida: 0.843\n",
            "[4, 300] pérdida: 0.849\n",
            "[4, 400] pérdida: 0.851\n",
            "[4, 500] pérdida: 0.864\n",
            "[4, 600] pérdida: 0.862\n",
            "Precisión en validación: 55.94%\n",
            "Época 5\n",
            "[5, 100] pérdida: 0.906\n",
            "[5, 200] pérdida: 0.832\n",
            "[5, 300] pérdida: 0.828\n",
            "[5, 400] pérdida: 0.857\n",
            "[5, 500] pérdida: 0.847\n",
            "[5, 600] pérdida: 0.852\n",
            "Precisión en validación: 55.68%\n",
            "Época 6\n",
            "[6, 100] pérdida: 0.850\n",
            "[6, 200] pérdida: 0.882\n",
            "[6, 300] pérdida: 0.866\n",
            "[6, 400] pérdida: 0.854\n",
            "[6, 500] pérdida: 0.854\n",
            "[6, 600] pérdida: 0.849\n",
            "Precisión en validación: 56.02%\n",
            "Época 7\n",
            "[7, 100] pérdida: 0.847\n",
            "[7, 200] pérdida: 0.867\n",
            "[7, 300] pérdida: 0.887\n",
            "[7, 400] pérdida: 0.860\n",
            "[7, 500] pérdida: 0.841\n",
            "[7, 600] pérdida: 0.867\n",
            "Precisión en validación: 56.50%\n",
            "Época 8\n",
            "[8, 100] pérdida: 0.858\n",
            "[8, 200] pérdida: 0.854\n",
            "[8, 300] pérdida: 0.822\n",
            "[8, 400] pérdida: 0.825\n",
            "[8, 500] pérdida: 0.871\n",
            "[8, 600] pérdida: 0.861\n",
            "Precisión en validación: 56.44%\n",
            "Época 9\n",
            "[9, 100] pérdida: 0.865\n",
            "[9, 200] pérdida: 0.866\n",
            "[9, 300] pérdida: 0.864\n",
            "[9, 400] pérdida: 0.877\n",
            "[9, 500] pérdida: 0.840\n",
            "[9, 600] pérdida: 0.844\n",
            "Precisión en validación: 56.64%\n",
            "Época 10\n",
            "[10, 100] pérdida: 0.836\n",
            "[10, 200] pérdida: 0.854\n",
            "[10, 300] pérdida: 0.847\n",
            "[10, 400] pérdida: 0.860\n",
            "[10, 500] pérdida: 0.870\n",
            "[10, 600] pérdida: 0.856\n",
            "Precisión en validación: 56.58%\n",
            "Época 11\n",
            "[11, 100] pérdida: 0.845\n",
            "[11, 200] pérdida: 0.858\n",
            "[11, 300] pérdida: 0.857\n",
            "[11, 400] pérdida: 0.856\n",
            "[11, 500] pérdida: 0.877\n",
            "[11, 600] pérdida: 0.860\n",
            "Precisión en validación: 55.32%\n",
            "Época 12\n",
            "[12, 100] pérdida: 0.874\n",
            "[12, 200] pérdida: 0.859\n",
            "[12, 300] pérdida: 0.824\n",
            "[12, 400] pérdida: 0.860\n",
            "[12, 500] pérdida: 0.866\n",
            "[12, 600] pérdida: 0.868\n",
            "Precisión en validación: 55.88%\n",
            "Época 13\n",
            "[13, 100] pérdida: 0.829\n",
            "[13, 200] pérdida: 0.869\n",
            "[13, 300] pérdida: 0.839\n",
            "[13, 400] pérdida: 0.865\n",
            "[13, 500] pérdida: 0.873\n",
            "[13, 600] pérdida: 0.842\n",
            "Precisión en validación: 56.04%\n",
            "Época 14\n",
            "[14, 100] pérdida: 0.867\n",
            "[14, 200] pérdida: 0.841\n",
            "[14, 300] pérdida: 0.847\n",
            "[14, 400] pérdida: 0.852\n",
            "[14, 500] pérdida: 0.855\n",
            "[14, 600] pérdida: 0.853\n",
            "Precisión en validación: 56.22%\n",
            "Época 15\n",
            "[15, 100] pérdida: 0.860\n",
            "[15, 200] pérdida: 0.839\n",
            "[15, 300] pérdida: 0.848\n",
            "[15, 400] pérdida: 0.845\n",
            "[15, 500] pérdida: 0.873\n",
            "[15, 600] pérdida: 0.872\n",
            "Precisión en validación: 55.82%\n",
            "Época 16\n",
            "[16, 100] pérdida: 0.843\n",
            "[16, 200] pérdida: 0.842\n",
            "[16, 300] pérdida: 0.844\n",
            "[16, 400] pérdida: 0.853\n",
            "[16, 500] pérdida: 0.859\n",
            "[16, 600] pérdida: 0.880\n",
            "Precisión en validación: 55.82%\n",
            "Época 17\n",
            "[17, 100] pérdida: 0.816\n",
            "[17, 200] pérdida: 0.876\n",
            "[17, 300] pérdida: 0.880\n",
            "[17, 400] pérdida: 0.840\n",
            "[17, 500] pérdida: 0.865\n",
            "[17, 600] pérdida: 0.862\n",
            "Precisión en validación: 55.78%\n",
            "Época 18\n",
            "[18, 100] pérdida: 0.853\n",
            "[18, 200] pérdida: 0.876\n",
            "[18, 300] pérdida: 0.872\n",
            "[18, 400] pérdida: 0.858\n",
            "[18, 500] pérdida: 0.862\n",
            "[18, 600] pérdida: 0.852\n",
            "Precisión en validación: 56.46%\n",
            "Época 19\n",
            "[19, 100] pérdida: 0.871\n",
            "[19, 200] pérdida: 0.875\n",
            "[19, 300] pérdida: 0.844\n",
            "[19, 400] pérdida: 0.850\n",
            "[19, 500] pérdida: 0.836\n",
            "[19, 600] pérdida: 0.832\n",
            "Precisión en validación: 56.60%\n",
            "Época 20\n",
            "[20, 100] pérdida: 0.828\n",
            "[20, 200] pérdida: 0.852\n",
            "[20, 300] pérdida: 0.863\n",
            "[20, 400] pérdida: 0.858\n",
            "[20, 500] pérdida: 0.860\n",
            "[20, 600] pérdida: 0.886\n",
            "Precisión en validación: 56.54%\n",
            "Época 21\n",
            "[21, 100] pérdida: 0.852\n",
            "[21, 200] pérdida: 0.847\n",
            "[21, 300] pérdida: 0.862\n",
            "[21, 400] pérdida: 0.844\n",
            "[21, 500] pérdida: 0.878\n",
            "[21, 600] pérdida: 0.864\n",
            "Precisión en validación: 56.66%\n",
            "Época 22\n",
            "[22, 100] pérdida: 0.869\n",
            "[22, 200] pérdida: 0.844\n",
            "[22, 300] pérdida: 0.852\n",
            "[22, 400] pérdida: 0.845\n",
            "[22, 500] pérdida: 0.855\n",
            "[22, 600] pérdida: 0.851\n",
            "Precisión en validación: 56.06%\n",
            "Época 23\n",
            "[23, 100] pérdida: 0.845\n",
            "[23, 200] pérdida: 0.850\n",
            "[23, 300] pérdida: 0.858\n",
            "[23, 400] pérdida: 0.871\n",
            "[23, 500] pérdida: 0.855\n",
            "[23, 600] pérdida: 0.866\n",
            "Precisión en validación: 56.80%\n",
            "Época 24\n",
            "[24, 100] pérdida: 0.841\n",
            "[24, 200] pérdida: 0.844\n",
            "[24, 300] pérdida: 0.852\n",
            "[24, 400] pérdida: 0.863\n",
            "[24, 500] pérdida: 0.849\n",
            "[24, 600] pérdida: 0.841\n",
            "Precisión en validación: 56.30%\n",
            "Época 25\n",
            "[25, 100] pérdida: 0.839\n",
            "[25, 200] pérdida: 0.842\n",
            "[25, 300] pérdida: 0.844\n",
            "[25, 400] pérdida: 0.870\n",
            "[25, 500] pérdida: 0.868\n",
            "[25, 600] pérdida: 0.853\n",
            "Precisión en validación: 56.08%\n",
            "Época 26\n",
            "[26, 100] pérdida: 0.864\n",
            "[26, 200] pérdida: 0.829\n",
            "[26, 300] pérdida: 0.861\n",
            "[26, 400] pérdida: 0.848\n",
            "[26, 500] pérdida: 0.866\n",
            "[26, 600] pérdida: 0.842\n",
            "Precisión en validación: 56.20%\n",
            "Época 27\n",
            "[27, 100] pérdida: 0.861\n",
            "[27, 200] pérdida: 0.841\n",
            "[27, 300] pérdida: 0.846\n",
            "[27, 400] pérdida: 0.856\n",
            "[27, 500] pérdida: 0.850\n",
            "[27, 600] pérdida: 0.882\n",
            "Precisión en validación: 56.98%\n",
            "Época 28\n",
            "[28, 100] pérdida: 0.845\n",
            "[28, 200] pérdida: 0.868\n",
            "[28, 300] pérdida: 0.866\n",
            "[28, 400] pérdida: 0.853\n",
            "[28, 500] pérdida: 0.832\n",
            "[28, 600] pérdida: 0.848\n",
            "Precisión en validación: 57.00%\n",
            "Época 29\n",
            "[29, 100] pérdida: 0.840\n",
            "[29, 200] pérdida: 0.867\n",
            "[29, 300] pérdida: 0.860\n",
            "[29, 400] pérdida: 0.852\n",
            "[29, 500] pérdida: 0.852\n",
            "[29, 600] pérdida: 0.837\n",
            "Precisión en validación: 56.12%\n",
            "Época 30\n",
            "[30, 100] pérdida: 0.848\n",
            "[30, 200] pérdida: 0.849\n",
            "[30, 300] pérdida: 0.886\n",
            "[30, 400] pérdida: 0.859\n",
            "[30, 500] pérdida: 0.839\n",
            "[30, 600] pérdida: 0.847\n",
            "Precisión en validación: 56.16%\n",
            "Época 31\n",
            "[31, 100] pérdida: 0.861\n",
            "[31, 200] pérdida: 0.857\n",
            "[31, 300] pérdida: 0.865\n",
            "[31, 400] pérdida: 0.865\n",
            "[31, 500] pérdida: 0.830\n",
            "[31, 600] pérdida: 0.875\n",
            "Precisión en validación: 56.54%\n",
            "Época 32\n",
            "[32, 100] pérdida: 0.851\n",
            "[32, 200] pérdida: 0.821\n",
            "[32, 300] pérdida: 0.879\n",
            "[32, 400] pérdida: 0.880\n",
            "[32, 500] pérdida: 0.839\n",
            "[32, 600] pérdida: 0.843\n",
            "Precisión en validación: 55.84%\n",
            "Época 33\n",
            "[33, 100] pérdida: 0.850\n",
            "[33, 200] pérdida: 0.836\n",
            "[33, 300] pérdida: 0.847\n",
            "[33, 400] pérdida: 0.855\n",
            "[33, 500] pérdida: 0.866\n",
            "[33, 600] pérdida: 0.886\n",
            "Precisión en validación: 55.92%\n",
            "Época 34\n",
            "[34, 100] pérdida: 0.859\n",
            "[34, 200] pérdida: 0.864\n",
            "[34, 300] pérdida: 0.849\n",
            "[34, 400] pérdida: 0.857\n",
            "[34, 500] pérdida: 0.852\n",
            "[34, 600] pérdida: 0.839\n",
            "Precisión en validación: 56.04%\n",
            "Época 35\n",
            "[35, 100] pérdida: 0.861\n",
            "[35, 200] pérdida: 0.855\n",
            "[35, 300] pérdida: 0.848\n",
            "[35, 400] pérdida: 0.882\n",
            "[35, 500] pérdida: 0.881\n",
            "[35, 600] pérdida: 0.860\n",
            "Precisión en validación: 56.36%\n",
            "Época 36\n",
            "[36, 100] pérdida: 0.842\n",
            "[36, 200] pérdida: 0.871\n",
            "[36, 300] pérdida: 0.865\n",
            "[36, 400] pérdida: 0.851\n",
            "[36, 500] pérdida: 0.861\n",
            "[36, 600] pérdida: 0.855\n",
            "Precisión en validación: 56.56%\n",
            "Época 37\n",
            "[37, 100] pérdida: 0.859\n",
            "[37, 200] pérdida: 0.854\n",
            "[37, 300] pérdida: 0.866\n",
            "[37, 400] pérdida: 0.855\n",
            "[37, 500] pérdida: 0.839\n",
            "[37, 600] pérdida: 0.833\n",
            "Precisión en validación: 56.60%\n",
            "Época 38\n",
            "[38, 100] pérdida: 0.856\n",
            "[38, 200] pérdida: 0.859\n",
            "[38, 300] pérdida: 0.859\n",
            "[38, 400] pérdida: 0.868\n",
            "[38, 500] pérdida: 0.851\n",
            "[38, 600] pérdida: 0.850\n",
            "Precisión en validación: 56.48%\n",
            "Época 39\n",
            "[39, 100] pérdida: 0.833\n",
            "[39, 200] pérdida: 0.859\n",
            "[39, 300] pérdida: 0.854\n",
            "[39, 400] pérdida: 0.836\n",
            "[39, 500] pérdida: 0.875\n",
            "[39, 600] pérdida: 0.852\n",
            "Precisión en validación: 56.56%\n",
            "Época 40\n",
            "[40, 100] pérdida: 0.826\n",
            "[40, 200] pérdida: 0.864\n",
            "[40, 300] pérdida: 0.865\n",
            "[40, 400] pérdida: 0.867\n",
            "[40, 500] pérdida: 0.846\n",
            "[40, 600] pérdida: 0.865\n",
            "Precisión en validación: 56.42%\n",
            "Época 41\n",
            "[41, 100] pérdida: 0.844\n",
            "[41, 200] pérdida: 0.858\n",
            "[41, 300] pérdida: 0.864\n",
            "[41, 400] pérdida: 0.857\n",
            "[41, 500] pérdida: 0.821\n",
            "[41, 600] pérdida: 0.869\n",
            "Precisión en validación: 56.24%\n",
            "Época 42\n",
            "[42, 100] pérdida: 0.859\n",
            "[42, 200] pérdida: 0.849\n",
            "[42, 300] pérdida: 0.868\n",
            "[42, 400] pérdida: 0.835\n",
            "[42, 500] pérdida: 0.869\n",
            "[42, 600] pérdida: 0.842\n",
            "Precisión en validación: 55.98%\n",
            "Época 43\n",
            "[43, 100] pérdida: 0.847\n",
            "[43, 200] pérdida: 0.844\n",
            "[43, 300] pérdida: 0.851\n",
            "[43, 400] pérdida: 0.846\n",
            "[43, 500] pérdida: 0.867\n",
            "[43, 600] pérdida: 0.825\n",
            "Precisión en validación: 56.74%\n",
            "Época 44\n",
            "[44, 100] pérdida: 0.832\n",
            "[44, 200] pérdida: 0.846\n",
            "[44, 300] pérdida: 0.866\n",
            "[44, 400] pérdida: 0.867\n",
            "[44, 500] pérdida: 0.875\n",
            "[44, 600] pérdida: 0.854\n",
            "Precisión en validación: 57.08%\n",
            "Época 45\n",
            "[45, 100] pérdida: 0.856\n",
            "[45, 200] pérdida: 0.855\n",
            "[45, 300] pérdida: 0.850\n",
            "[45, 400] pérdida: 0.867\n",
            "[45, 500] pérdida: 0.820\n",
            "[45, 600] pérdida: 0.840\n",
            "Precisión en validación: 56.44%\n",
            "Época 46\n",
            "[46, 100] pérdida: 0.848\n",
            "[46, 200] pérdida: 0.845\n",
            "[46, 300] pérdida: 0.854\n",
            "[46, 400] pérdida: 0.872\n",
            "[46, 500] pérdida: 0.843\n",
            "[46, 600] pérdida: 0.833\n",
            "Precisión en validación: 56.00%\n",
            "Época 47\n",
            "[47, 100] pérdida: 0.888\n",
            "[47, 200] pérdida: 0.835\n",
            "[47, 300] pérdida: 0.856\n",
            "[47, 400] pérdida: 0.870\n",
            "[47, 500] pérdida: 0.836\n",
            "[47, 600] pérdida: 0.872\n",
            "Precisión en validación: 56.04%\n",
            "Época 48\n",
            "[48, 100] pérdida: 0.868\n",
            "[48, 200] pérdida: 0.857\n",
            "[48, 300] pérdida: 0.856\n",
            "[48, 400] pérdida: 0.878\n",
            "[48, 500] pérdida: 0.836\n",
            "[48, 600] pérdida: 0.852\n",
            "Precisión en validación: 56.44%\n",
            "Época 49\n",
            "[49, 100] pérdida: 0.856\n",
            "[49, 200] pérdida: 0.835\n",
            "[49, 300] pérdida: 0.848\n",
            "[49, 400] pérdida: 0.845\n",
            "[49, 500] pérdida: 0.872\n",
            "[49, 600] pérdida: 0.865\n",
            "Precisión en validación: 56.00%\n",
            "Época 50\n",
            "[50, 100] pérdida: 0.858\n",
            "[50, 200] pérdida: 0.857\n",
            "[50, 300] pérdida: 0.847\n",
            "[50, 400] pérdida: 0.873\n",
            "[50, 500] pérdida: 0.862\n",
            "[50, 600] pérdida: 0.854\n",
            "Precisión en validación: 56.72%\n"
          ]
        }
      ],
      "source": [
        "# Función de validación para comprobar precisión\n",
        "def validate_model():\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in valloader:\n",
        "            images, labels = data\n",
        "            images, labels = images.cuda(), labels.cuda()\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Precisión en validación: {100 * correct / total:.2f}%')\n",
        "    return correct / total\n",
        "\n",
        "# Entrenar el modelo\n",
        "epochs = 50\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Época {epoch+1}\")\n",
        "    train_model(epoch)\n",
        "    acc = validate_model()\n",
        "\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        # Guardar el mejor modelo\n",
        "        torch.save(model.state_dict(), 'cifar100_best_model.pkl')\n",
        "\n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6yysm1ZgqKt",
        "outputId": "be97b338-6ac1-47a1-f56d-d6cc5c4879dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precisión final en los datos de prueba: 58.34%\n"
          ]
        }
      ],
      "source": [
        "# Evaluación final en el conjunto de prueba\n",
        "def test_model():\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            images, labels = images.cuda(), labels.cuda()\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Precisión final en los datos de prueba: {100 * correct / total:.2f}%')\n",
        "\n",
        "test_model()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
